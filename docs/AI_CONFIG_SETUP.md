# AI配置管理功能

## 功能概述

新增的AI配置管理功能允许用户自定义配置多个AI服务提供商和模型，实现更灵活的AI聊天体验。

## 主要特性

### 1. 多AI提供商支持
- **OpenAI**: 支持GPT系列模型
- **SiliconFlow**: 硅流科技AI服务
- **FreeGPT**: 免费GPT服务
- **通义千问**: 阿里云AI服务
- **Gemini**: Google AI服务
- **Claude**: Anthropic AI服务
- **自定义**: 支持任何兼容OpenAI API的服务

### 2. 模型管理
- 为每个提供商配置多个模型
- 自动检测可用模型
- 配置模型参数（最大Token、功能支持等）
- 灵活启用/禁用模型

### 3. API测试和验证
- 一键测试API连接
- 自动检测可用模型
- 批量导入检测到的模型

## 使用指南

### 第一步：配置AI服务提供商

1. 进入 **AI配置** 页面
2. 点击 **添加AI提供商**
3. 填写配置信息：
   - **提供商名称**: 自定义名称，如"我的OpenAI"
   - **提供商类型**: 选择对应的服务类型
   - **API密钥**: 输入您的API密钥
   - **API基础地址**: 输入API端点URL
   - **配置选项**: 设置是否启用和是否为默认

4. 点击 **测试连接** 验证配置
5. 保存配置

### 第二步：添加AI模型

**方式一：自动检测（推荐）**
1. 在提供商卡片中点击 **检测模型** 按钮
2. 系统自动获取可用模型列表
3. 选择需要的模型进行批量导入

**方式二：手动添加**
1. 切换到 **AI模型** 标签页
2. 点击 **添加模型**
3. 选择对应的提供商
4. 填写模型配置信息
5. 保存模型

### 第三步：在聊天中使用

1. 进入 **AI聊天** 页面
2. 点击设置按钮打开聊天设置
3. 选择要使用的AI提供商和模型
4. 调整其他参数（最大Token、创造性等）
5. 开始聊天

## 配置示例

### OpenAI配置
```
提供商名称: OpenAI官方
提供商类型: OpenAI
API密钥: sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
API基础地址: https://api.openai.com/v1
```

### SiliconFlow配置
```
提供商名称: SiliconFlow
提供商类型: SiliconFlow
API密钥: sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
API基础地址: https://api.siliconflow.cn/v1
```

### 自定义配置（如本地部署的模型）
```
提供商名称: 本地Ollama
提供商类型: 自定义
API密钥: ollama
API基础地址: http://localhost:11434/v1
```

## 注意事项

1. **API密钥安全**: API密钥将加密存储，但请确保使用具有适当权限的密钥

2. **模型限制**: 不同模型有不同的Token限制和功能支持，请根据实际需求选择

3. **费用控制**: 使用付费API时请注意Token消耗，避免产生意外费用

4. **网络连接**: 确保服务器能够访问对应的API端点

5. **兼容性**: 自定义提供商需要兼容OpenAI API格式

## 故障排除

### API连接失败
- 检查API密钥是否正确
- 验证API基础地址格式
- 确认网络连接正常
- 检查API服务状态

### 模型检测失败
- 确认API连接正常
- 检查API密钥权限
- 验证提供商是否支持模型列表API

### 聊天无响应
- 检查选择的模型是否启用
- 确认提供商配置正确
- 查看浏览器控制台错误信息

## 技术实现

- 后端使用Django REST Framework提供API
- 前端使用React + Ant Design构建界面
- 支持OpenAI SDK兼容的所有AI服务
- 数据库存储用户配置信息
- 支持实时配置切换

## 更新日志

### v1.0.0 (当前版本)
- 初始版本发布
- 支持多AI提供商配置
- 实现模型自动检测
- 添加API连接测试功能
- 集成聊天设置界面
