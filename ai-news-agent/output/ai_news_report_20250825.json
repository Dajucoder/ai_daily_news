{
  "summary": "ä»Šæ—¥AIé¢†åŸŸä¸»è¦èšç„¦äºç ”ç©¶è¿›å±•å’ŒæŠ€æœ¯åº”ç”¨ã€‚åœ¨ç ”ç©¶è¿›å±•æ–¹é¢ï¼Œæœ‰6ç¯‡æ–°é—»æŠ¥é“äº†JAXåœ¨åTransformeræ—¶ä»£çš„è¿›å±•ã€å¦‚ä½•å¹³è¡¡è®­ç»ƒæ•°æ®é›†ä»¥æ”¹è¿›å¤šç±»åˆ«åˆ†ç±»æ¨¡å‹ã€AIä»£ç†é€‰æ‹©åˆé€‚çš„Foundation Modelsçš„æ–¹æ³•ã€æ¢ç´¢æœ¬åœ°ä¼˜å…ˆçš„äººå·¥æ™ºèƒ½å·¥ä½œæµè‡ªåŠ¨åŒ–ä»¥åŠéçº¿æ€§æœ‰ç†ç‰¹å¾å˜æ¢ä¸­çš„æç‚¹ä½ç½®é€‰æ‹©ç­‰å†…å®¹ã€‚æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€æ¡å…³äºæŠ€æœ¯çªç ´çš„æ–°é—»ï¼Œè¿›ä¸€æ­¥æ¨åŠ¨äº†AIæŠ€æœ¯çš„å‘å±•ã€‚è¿™äº›æŠ¥é“å±•ç¤ºäº†AIç ”ç©¶å’Œåº”ç”¨çš„å¹¿æ³›æ¢ç´¢å’Œæ·±å…¥å‘å±•ã€‚",
  "total_count": 8,
  "category_stats": {
    "research_progress": 6,
    "tech_breakthrough": 1,
    "other": 1
  },
  "importance_stats": {
    "medium": 7,
    "low": 1
  },
  "top_stories": [
    {
      "title": "JAXåœ¨åTransformeræ—¶ä»£çš„è¿›å±•å¦‚ä½•ï¼Ÿ",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1mybwih/d_how_did_jax_fare_in_the_post_transformer_world/",
      "summary": "è¿‘å¹´æ¥ï¼ŒJAXæ›¾å› Transformeræ¨¡å‹çš„å…´èµ·è€Œå¤‡å—å…³æ³¨ï¼Œç”šè‡³æœ‰è§‚ç‚¹è®¤ä¸ºå®ƒå¯èƒ½é¢ è¦†PyTorchçš„åœ°ä½ã€‚ç„¶è€Œï¼Œéšç€å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å’Œè¯­è¨€æ¨¡å‹çƒ­æ½®çš„å…´èµ·ï¼Œå…³äºJAXçš„è®¨è®ºå’Œå¼€å‘æ´»åŠ¨æœ‰æ‰€å‡å°‘ã€‚æœ¬æ–‡ä½œè€…è®¤ä¸ºï¼Œå°½ç®¡ç›®å‰JAXçš„å‘å±•ä¼¼ä¹ä¸å¦‚ä»å‰ï¼Œä½†å¯¹äºå…³æ³¨ç‰¹å®šç ”ç©¶å’Œè¡Œä¸šéœ€æ±‚çš„äººæ¥è¯´ï¼Œå®ƒä»ç„¶å…·æœ‰æ½œåŠ›å’Œä»·å€¼ã€‚",
      "content": "A few years ago, there was a lot of buzz around JAX, with some enthusiasts going as far as saying it would disrupt PyTorch. Every now and then, some big AI lab would release stuff in JAX or a PyTorch dev would write a post about it, and some insightful and inspired discourse would ensue with big prospects. However, chatter and development have considerably quieted down since transformers, large multimodal models, and the ongoing LLM fever. Is it still promising? Or at least, this is my impression, which I concede might be myopic due to my research and industry needs. submitted by /u/TajineMaster159 [link] [comments]",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "JAXæ›¾å› èƒ½ä¸PyTorchç«äº‰è€Œå—åˆ°å…³æ³¨ï¼Œä½†éšç€Transformerå’Œå¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„å…´èµ·ï¼Œç›¸å…³è®¨è®ºå’Œå¼€å‘æ´»åŠ¨æœ‰æ‰€å‡å°‘",
        "JAXåœ¨åTransformeræ—¶ä»£çš„å‘å±•æƒ…å†µå­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œä½œè€…è®¤ä¸ºè¿™å¯èƒ½ä¸å…¶ç ”ç©¶å’Œè¡Œä¸šéœ€æ±‚æœ‰å…³ï¼Œæ˜¾å¾—è¾ƒä¸ºç‰‡é¢",
        "JAXåœ¨é¢å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çƒ­æ½®æ—¶ï¼Œå…¶åº”ç”¨å‰æ™¯å’Œè¡Œä¸šå½±å“åŠ›å¯èƒ½å—åˆ°äº†ä¸€å®šå½±å“"
      ],
      "tags": [
        "MachineLearning",
        "JAX",
        "Transformer",
        "AIå‘å±•",
        "ç ”ç©¶è¿›å±•",
        "æœºå™¨å­¦ä¹ "
      ],
      "processed_time": "2025-08-25T03:16:49.999460+08:00",
      "is_today_news": true
    },
    {
      "title": "å¦‚ä½•å¹³è¡¡è®­ç»ƒæ•°æ®é›†ä»¥æ”¹è¿›å¤šç±»åˆ«åˆ†ç±»æ¨¡å‹",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1mywuni/p_options_on_how_to_balance_my_training_dataset/",
      "summary": "ä½œè€…æ­£åœ¨å¼€å‘ä¸€ä¸ªä½¿ç”¨Pythonçš„æœºå™¨å­¦ä¹ åˆ†ç±»é¡¹ç›®ï¼Œæ•°æ®é›†åŒ…å«5ä¸ªç±»åˆ«ï¼Œä½†ä¸¥é‡ä¸å¹³è¡¡ï¼Œå¯¼è‡´æ¨¡å‹åå‘å¤šæ•°ç±»åˆ«ã€‚å°è¯•ä½¿ç”¨SMOTETomekè¿›è¡Œè¿‡é‡‡æ ·åæ•ˆæœä¸ä½³ã€‚ä½œè€…å¸Œæœ›æ”¹è¿›æ¨¡å‹ä»¥æ›´å¥½åœ°å­¦ä¹ å°‘æ•°ç±»åˆ«çš„ç‰¹å¾ï¼Œå¯»æ±‚å…¶ä»–å¹³è¡¡è®­ç»ƒæ•°æ®é›†çš„æ–¹æ³•ã€‚é¡¹ç›®å°†ä½¿ç”¨åŒ…æ‹¬éšæœºæ£®æ—ã€å†³ç­–æ ‘ç­‰åœ¨å†…çš„6ç§åˆ†ç±»æ¨¡å‹ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚",
      "content": "I'm working on developing a ML classification project using Python, divided into 5 output categories (classes). However, my training dataset is extremely unbalanced, and my results always lean toward the dominant class (class 5, as expected). However, I wanted my models to better learn the characteristics of the other classes, and I realized that one way to do this is by balancing the training dataset. I tried using SMOTETomek for oversampling, but my models didn't respond well. Does anyone have any ideas or possibilities for balancing my training dataset? There are 6 classification ML models that will ultimately be combined into an ensemble. The models used are: RandomForest, DecisionTree, ExtraTrees, AdaBoost, NaiveBayes, KNN, GradientBoosting, and SVM. The data is also being standardized via standardSCaler. Total record count by category: Category 1: 160 records Category 2: 446 records Category 3: 605 records Category 4: 3,969 records Category 5: 47,874 records submitted by /u/Pedro",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "é¡¹ç›®æ¶‰åŠ5ä¸ªè¾“å‡ºç±»åˆ«ï¼Œä½†è®­ç»ƒæ•°æ®é›†ä¸¥é‡ä¸å¹³è¡¡ï¼Œå¯¼è‡´æ¨¡å‹åå‘å¤šæ•°ç±»åˆ«è¿›è¡Œé¢„æµ‹",
        "å°è¯•ä½¿ç”¨SMOTETomekè¿›è¡Œè¿‡é‡‡æ ·ä»¥å¹³è¡¡æ•°æ®é›†ï¼Œä½†æ•ˆæœä¸ä½³",
        "è®¡åˆ’ä½¿ç”¨åŒ…æ‹¬éšæœºæ£®æ—ã€å†³ç­–æ ‘ç­‰åœ¨å†…çš„6ç§åˆ†ç±»æœºå™¨å­¦ä¹ æ¨¡å‹æ„å»ºé›†æˆæ¨¡å‹"
      ],
      "tags": [
        "MachineLearning",
        "æœºå™¨å­¦ä¹ ",
        "æ•°æ®ä¸å¹³è¡¡",
        "æ¨¡å‹ä¼˜åŒ–",
        "åˆ†ç±»æ¨¡å‹",
        "SMOTETomek"
      ],
      "processed_time": "2025-08-25T03:17:39.595137+08:00",
      "is_today_news": true
    }
  ],
  "all_news": [
    {
      "title": "JAXåœ¨åTransformeræ—¶ä»£çš„è¿›å±•å¦‚ä½•ï¼Ÿ",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1mybwih/d_how_did_jax_fare_in_the_post_transformer_world/",
      "summary": "è¿‘å¹´æ¥ï¼ŒJAXæ›¾å› Transformeræ¨¡å‹çš„å…´èµ·è€Œå¤‡å—å…³æ³¨ï¼Œç”šè‡³æœ‰è§‚ç‚¹è®¤ä¸ºå®ƒå¯èƒ½é¢ è¦†PyTorchçš„åœ°ä½ã€‚ç„¶è€Œï¼Œéšç€å¤§å‹å¤šæ¨¡æ€æ¨¡å‹å’Œè¯­è¨€æ¨¡å‹çƒ­æ½®çš„å…´èµ·ï¼Œå…³äºJAXçš„è®¨è®ºå’Œå¼€å‘æ´»åŠ¨æœ‰æ‰€å‡å°‘ã€‚æœ¬æ–‡ä½œè€…è®¤ä¸ºï¼Œå°½ç®¡ç›®å‰JAXçš„å‘å±•ä¼¼ä¹ä¸å¦‚ä»å‰ï¼Œä½†å¯¹äºå…³æ³¨ç‰¹å®šç ”ç©¶å’Œè¡Œä¸šéœ€æ±‚çš„äººæ¥è¯´ï¼Œå®ƒä»ç„¶å…·æœ‰æ½œåŠ›å’Œä»·å€¼ã€‚",
      "content": "A few years ago, there was a lot of buzz around JAX, with some enthusiasts going as far as saying it would disrupt PyTorch. Every now and then, some big AI lab would release stuff in JAX or a PyTorch dev would write a post about it, and some insightful and inspired discourse would ensue with big prospects. However, chatter and development have considerably quieted down since transformers, large multimodal models, and the ongoing LLM fever. Is it still promising? Or at least, this is my impression, which I concede might be myopic due to my research and industry needs. submitted by /u/TajineMaster159 [link] [comments]",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "JAXæ›¾å› èƒ½ä¸PyTorchç«äº‰è€Œå—åˆ°å…³æ³¨ï¼Œä½†éšç€Transformerå’Œå¤§å‹å¤šæ¨¡æ€æ¨¡å‹çš„å…´èµ·ï¼Œç›¸å…³è®¨è®ºå’Œå¼€å‘æ´»åŠ¨æœ‰æ‰€å‡å°‘",
        "JAXåœ¨åTransformeræ—¶ä»£çš„å‘å±•æƒ…å†µå­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œä½œè€…è®¤ä¸ºè¿™å¯èƒ½ä¸å…¶ç ”ç©¶å’Œè¡Œä¸šéœ€æ±‚æœ‰å…³ï¼Œæ˜¾å¾—è¾ƒä¸ºç‰‡é¢",
        "JAXåœ¨é¢å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çƒ­æ½®æ—¶ï¼Œå…¶åº”ç”¨å‰æ™¯å’Œè¡Œä¸šå½±å“åŠ›å¯èƒ½å—åˆ°äº†ä¸€å®šå½±å“"
      ],
      "tags": [
        "MachineLearning",
        "JAX",
        "Transformer",
        "AIå‘å±•",
        "ç ”ç©¶è¿›å±•",
        "æœºå™¨å­¦ä¹ "
      ],
      "processed_time": "2025-08-25T03:16:49.999460+08:00",
      "is_today_news": true
    },
    {
      "title": "å¦‚ä½•å¹³è¡¡è®­ç»ƒæ•°æ®é›†ä»¥æ”¹è¿›å¤šç±»åˆ«åˆ†ç±»æ¨¡å‹",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1mywuni/p_options_on_how_to_balance_my_training_dataset/",
      "summary": "ä½œè€…æ­£åœ¨å¼€å‘ä¸€ä¸ªä½¿ç”¨Pythonçš„æœºå™¨å­¦ä¹ åˆ†ç±»é¡¹ç›®ï¼Œæ•°æ®é›†åŒ…å«5ä¸ªç±»åˆ«ï¼Œä½†ä¸¥é‡ä¸å¹³è¡¡ï¼Œå¯¼è‡´æ¨¡å‹åå‘å¤šæ•°ç±»åˆ«ã€‚å°è¯•ä½¿ç”¨SMOTETomekè¿›è¡Œè¿‡é‡‡æ ·åæ•ˆæœä¸ä½³ã€‚ä½œè€…å¸Œæœ›æ”¹è¿›æ¨¡å‹ä»¥æ›´å¥½åœ°å­¦ä¹ å°‘æ•°ç±»åˆ«çš„ç‰¹å¾ï¼Œå¯»æ±‚å…¶ä»–å¹³è¡¡è®­ç»ƒæ•°æ®é›†çš„æ–¹æ³•ã€‚é¡¹ç›®å°†ä½¿ç”¨åŒ…æ‹¬éšæœºæ£®æ—ã€å†³ç­–æ ‘ç­‰åœ¨å†…çš„6ç§åˆ†ç±»æ¨¡å‹ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ã€‚",
      "content": "I'm working on developing a ML classification project using Python, divided into 5 output categories (classes). However, my training dataset is extremely unbalanced, and my results always lean toward the dominant class (class 5, as expected). However, I wanted my models to better learn the characteristics of the other classes, and I realized that one way to do this is by balancing the training dataset. I tried using SMOTETomek for oversampling, but my models didn't respond well. Does anyone have any ideas or possibilities for balancing my training dataset? There are 6 classification ML models that will ultimately be combined into an ensemble. The models used are: RandomForest, DecisionTree, ExtraTrees, AdaBoost, NaiveBayes, KNN, GradientBoosting, and SVM. The data is also being standardized via standardSCaler. Total record count by category: Category 1: 160 records Category 2: 446 records Category 3: 605 records Category 4: 3,969 records Category 5: 47,874 records submitted by /u/Pedro",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "é¡¹ç›®æ¶‰åŠ5ä¸ªè¾“å‡ºç±»åˆ«ï¼Œä½†è®­ç»ƒæ•°æ®é›†ä¸¥é‡ä¸å¹³è¡¡ï¼Œå¯¼è‡´æ¨¡å‹åå‘å¤šæ•°ç±»åˆ«è¿›è¡Œé¢„æµ‹",
        "å°è¯•ä½¿ç”¨SMOTETomekè¿›è¡Œè¿‡é‡‡æ ·ä»¥å¹³è¡¡æ•°æ®é›†ï¼Œä½†æ•ˆæœä¸ä½³",
        "è®¡åˆ’ä½¿ç”¨åŒ…æ‹¬éšæœºæ£®æ—ã€å†³ç­–æ ‘ç­‰åœ¨å†…çš„6ç§åˆ†ç±»æœºå™¨å­¦ä¹ æ¨¡å‹æ„å»ºé›†æˆæ¨¡å‹"
      ],
      "tags": [
        "MachineLearning",
        "æœºå™¨å­¦ä¹ ",
        "æ•°æ®ä¸å¹³è¡¡",
        "æ¨¡å‹ä¼˜åŒ–",
        "åˆ†ç±»æ¨¡å‹",
        "SMOTETomek"
      ],
      "processed_time": "2025-08-25T03:17:39.595137+08:00",
      "is_today_news": true
    },
    {
      "title": "AIä»£ç†å¦‚ä½•é€‰æ‹©åˆé€‚çš„Foundation Modelsï¼Ÿ",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1myj9jk/r_routers_to_foundation_models/",
      "summary": "è¯¥æ–‡ç« æ¢è®¨äº†æ˜¯å¦éœ€è¦é¡¹ç›®æˆ–åŒ…æ¥å¸®åŠ©ç”¨æˆ·é€‰æ‹©åˆé€‚çš„â€œåŸºç¡€æ¨¡å‹â€ï¼ˆFMï¼‰ä»¥é€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ã€‚ä½œè€…ç‰¹åˆ«å…³æ³¨é‚£äº›åœ¨å·¥ä½œä¸­æˆ–ç ”ç©¶ä¸­è°ƒç”¨è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äººï¼Œæ˜¯å¦è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå®é™…éœ€æ±‚ï¼Œè¿˜æ˜¯ä»…ä»…æ˜¯ä¸€ç§â€œé”¦ä¸Šæ·»èŠ±â€çš„åŠŸèƒ½ã€‚æ–‡ç« æŒ‡å‡ºï¼Œé€šè¿‡åˆç†åˆ†é…ä»»åŠ¡ç»™ä¸åŒçš„åŸºç¡€æ¨¡å‹ï¼Œå¯ä»¥åœ¨ä¿è¯è´¨é‡çš„åŒæ—¶é™ä½æˆæœ¬ã€‚ä½œè€…è¿˜è¡¨è¾¾äº†å¯¹è¿™ç§æœºåˆ¶çš„å…´è¶£ï¼Œå¹¶è€ƒè™‘è‡ªè¡Œå¼€å‘ä¸€ä¸ªæ¨¡å‹è·¯ç”±å™¨ï¼Œä½†å¸Œæœ›å…ˆäº†è§£ç°æœ‰æŠ€æœ¯å’Œéœ€æ±‚æƒ…å†µã€‚",
      "content": "Are there any projects/packages that help inform an agent which FM to use for their use case? Curious if this is even a strong need in the AI community? Anyone have any experience with â€œroutersâ€? Update: especially curious about whether folks implementing LLM calls at work or for research (either one offs or agents) feel this as a real need or is it just a nice-to-know sort of thing? Intuitively, cutting costs while keeping quality high by routing to FMs that optimize for just that seems like a valid concern, but Iâ€™m trying to get a sense of how much of a concern it really is Of course, the mechanisms underlying this approach are of interest to me as well. Iâ€™m thinking of writing my own router, but would like to understand whatâ€™s out there/what the need even is first submitted by /u/electricsheeptacos [link] [comments]",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "ç”¨æˆ·åœ¨æ¢ç´¢æ˜¯å¦éœ€è¦æˆ–å¦‚ä½•ä½¿ç”¨'è·¯ç”±å™¨'æ¥æŒ‡å¯¼ä¸åŒåœºæ™¯ä¸‹é€‰æ‹©åˆé€‚çš„åŸºç¡€æ¨¡å‹ï¼Œä»¥é™ä½æˆæœ¬åŒæ—¶ä¿æŒé«˜è´¨é‡è¾“å‡º",
        "ç¤¾åŒºå¯¹è¿™ä¸€éœ€æ±‚çš„è®¤è¯†ä¸ä¸€ï¼Œæœ‰äººè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªå®é™…éœ€è¦ï¼Œæœ‰äººåˆ™è®¤ä¸ºå®ƒåªæ˜¯ä¸€ä¸ªé¢å¤–çš„åŠŸèƒ½",
        "ç”¨æˆ·è®¡åˆ’è‡ªå·±å¼€å‘ä¸€ä¸ªåŸºç¡€æ¨¡å‹è·¯ç”±å™¨ï¼Œä½†é¦–å…ˆå¸Œæœ›äº†è§£ç°æœ‰çš„è§£å†³æ–¹æ¡ˆå’Œéœ€æ±‚ç¨‹åº¦"
      ],
      "tags": [
        "MachineLearning",
        "AIä»£ç†",
        "Foundation Models",
        "æˆæœ¬ä¼˜åŒ–",
        "æ¨¡å‹é€‰æ‹©",
        "è·¯ç”±æœºåˆ¶"
      ],
      "processed_time": "2025-08-25T03:17:55.003431+08:00",
      "is_today_news": true
    },
    {
      "title": "æ¢ç´¢æœ¬åœ°ä¼˜å…ˆçš„äººå·¥æ™ºèƒ½å·¥ä½œæµè‡ªåŠ¨åŒ–",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1myr68a/d_exploring_localfirst_ai_workflow_automation/",
      "summary": "ä½œè€…æ¢ç´¢äº†ä¸€ç§å®Œå…¨æœ¬åœ°åŒ–çš„AIå·¥ä½œæµè‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œæ— éœ€ä¾èµ–äº‘ç«¯æœåŠ¡ï¼Œä½†ä»æ”¯æŒå®æ—¶æ•°æ®æºå’Œé›†æˆã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ä¸ºæœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½ç ”ç©¶æä¾›ä¸€ç§éšç§ä¼˜å…ˆã€èµ„æºé«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆï¼Œç‰¹åˆ«é€‚ç”¨äºéœ€è¦ä¸¥æ ¼éšç§ä¿æŠ¤ã€åˆè§„æ€§å’Œæˆæœ¬æ•ˆç›Šçš„æœºå™¨äººå’Œç‰©è”ç½‘ç³»ç»Ÿã€‚ä½œè€…å¸Œæœ›äº†è§£è¿™ç§æœ¬åœ°åŒ–AIå·¥ä½œæµåœ¨ç ”ç©¶ã€ä¼ä¸šåº”ç”¨å’Œç‰©è”ç½‘ç³»ç»Ÿä¸­çš„æ½œåœ¨å½±å“ï¼Œå¹¶é‚€è¯·ç ”ç©¶å’Œåº”ç”¨æœºå™¨å­¦ä¹ ç¤¾åŒºæä¾›åé¦ˆã€‚ç›¸å…³æŠ€æœ¯è¯¦è§å¼€æºé¡¹ç›®[Agentic Signal]ï¼ˆhttps://github.com/code-forge-temple/agentic-signalï¼‰ã€‚",
      "content": "[D] Exploring Local-First AI Workflow Automation Hi all, Iâ€™ve been experimenting with an open-source approach to AI workflow automation that runs entirely locally (no cloud dependencies), while still supporting real-time data sources and integrations. The goal is to provide a privacy-first, resource-efficient alternative to traditional cloud-heavy workflow tools like Zapier or n8n, but with LLM support integrated. ğŸ‘‰ My question for the community: How do you see local-first AI workflows impacting ML/AI research, enterprise adoption, and robotics/IoT systems where privacy, compliance, and cost efficiency are critical? Repo: Agentic Signal (open-source, AGPL v3 / commercial dual license) Demo video: YouTube link Would love feedback from both the research and applied ML communities on potential use cases, limitations, or challenges you foresee with this approach. Thanks! submitted by /u/Code-Forge-Temple [link] [comments]",
      "category": "tech_breakthrough",
      "importance": "medium",
      "key_points": [
        "è¯¥æ–‡ç« ä»‹ç»äº†ä¸€ç§å®Œå…¨æœ¬åœ°åŒ–çš„AIå·¥ä½œæµè‡ªåŠ¨åŒ–æ–¹æ³•ï¼Œä¸ä¾èµ–äº‘æœåŠ¡ï¼Œä½†ä»æ”¯æŒå®æ—¶æ•°æ®æºå’Œé›†æˆï¼Œå¼ºè°ƒäº†éšç§ä¼˜å…ˆå’Œèµ„æºæ•ˆç‡ã€‚",
        "è¿™ç§æœ¬åœ°ä¼˜å…ˆçš„AIå·¥ä½œæµæ—¨åœ¨ä½œä¸ºä¼ ç»Ÿäº‘ä¾èµ–å‹å·¥å…·ï¼ˆå¦‚Zapieræˆ–n8nï¼‰çš„éšç§ä¼˜å…ˆã€èµ„æºæ•ˆç‡æ›¿ä»£æ–¹æ¡ˆï¼ŒåŒæ—¶æ•´åˆäº†LLMæ”¯æŒã€‚",
        "è¯¥æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºéœ€è¦éšç§ã€åˆè§„æ€§å’Œæˆæœ¬æ•ˆç‡çš„æœºå™¨å­¦ä¹ /äººå·¥æ™ºèƒ½ç ”ç©¶ã€ä¼ä¸šé‡‡ç”¨ä»¥åŠæœºå™¨äºº/ç‰©è”ç½‘ç³»ç»Ÿã€‚"
      ],
      "tags": [
        "MachineLearning",
        "AIå·¥ä½œæµ",
        "æœ¬åœ°ä¼˜å…ˆ",
        "éšç§ä¿æŠ¤",
        "èµ„æºæ•ˆç‡",
        "å¼€æºé¡¹ç›®"
      ],
      "processed_time": "2025-08-25T03:18:29.639497+08:00",
      "is_today_news": true
    },
    {
      "title": "éçº¿æ€§æœ‰ç†ç‰¹å¾å˜æ¢ä¸­çš„æç‚¹ä½ç½®é€‰æ‹©",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1myoooy/d_poles_of_nonlinear_rational_features/",
      "summary": "ä½œè€…åœ¨è®¨è®ºå¦‚ä½•åœ¨æ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ï¼Œä½¿ç”¨éçº¿æ€§æœ‰ç†ç‰¹å¾ï¼ˆè€Œéæ ·æ¡å‡½æ•°ï¼‰è¿›è¡Œç‰¹å¾è½¬æ¢çš„é—®é¢˜ã€‚å…·ä½“è€Œè¨€ï¼Œä½œè€…é¢ä¸´ä¸€ä¸ªæŒ‘æˆ˜ï¼šå¦‚ä½•ç¡®å®šè¿™äº›æœ‰ç†å‡½æ•°çš„æç‚¹ä½ç½®ã€‚ä½œè€…çš„ç›®æ ‡æ˜¯åœ¨æ¨¡å‹é¢„å¤„ç†é˜¶æ®µä½¿ç”¨è¿™äº›æœ‰ç†ç‰¹å¾ï¼Œç±»ä¼¼äºScikit-Learnä¸­çš„MinMaxScaleræˆ–SplineTransformerã€‚ç¡®å®šæç‚¹ä½ç½®å¯¹æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒç›´æ¥å½±å“åˆ°ç‰¹å¾è½¬æ¢çš„æ•ˆæœã€‚è¿™ä¸ªé—®é¢˜å¯¹äºå¤„ç†æ—¶é—´ã€ç½‘ç«™è®¿é—®æ—¶é•¿æˆ–æ‹å–å‡ºä»·ç­‰éè´Ÿæ•°å€¼ç‰¹å¾å°¤ä¸ºé‡è¦ã€‚",
      "content": "Suppose I want to fit a linear model to non-linear rational features. Something like RationalTransformer instead of SplineTransformer in Scikit-Learn, that uses a basis of rational functions. The domain of my raw features before being transformed are (theoretically) unbounded non-negative numbers, such as \"time since X happened\", \"total time spent on the website\", or \"bid in an auction\". So here is the question: where would you put the poles? Why? Note, I'm not aiming on fitting one rational curve, so algorithms in the spirit of AAA are irrelevant. I'm aiming at a component I can use in a pipeline that transformes features before model fitting, such as MinMaxScaler or SplineTransformer in scikit-learn. submitted by /u/alexsht1 [link] [comments]",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "æ–‡ç« è®¨è®ºäº†åœ¨æ‹Ÿåˆéçº¿æ€§æœ‰ç†ç‰¹å¾æ—¶å¦‚ä½•åˆç†è®¾ç½®æœ‰ç†å‡½æ•°çš„æç‚¹ä½ç½®ï¼Œè¿™å¯¹äºæ„å»ºæœ‰æ•ˆçš„æœºå™¨å­¦ä¹ æ¨¡å‹è‡³å…³é‡è¦",
        "æå‡ºäº†ä½¿ç”¨æœ‰ç†å˜æ¢å™¨ï¼ˆRationalTransformerï¼‰æ›¿ä»£ä¼ ç»Ÿçš„æ ·æ¡å˜æ¢å™¨ï¼ˆSplineTransformerï¼‰ï¼Œä»¥é€‚åº”éè´Ÿæ•°å€¼ç‰¹å¾çš„æ•°æ®",
        "å¼ºè°ƒäº†åœ¨ç‰¹å¾é¢„å¤„ç†é˜¶æ®µåº”ç”¨è¿™ç§å˜æ¢å™¨çš„é‡è¦æ€§ï¼Œç±»ä¼¼äºMinMaxScaleræˆ–SplineTransformeråœ¨Scikit-Learnä¸­çš„åº”ç”¨"
      ],
      "tags": [
        "MachineLearning",
        "æœºå™¨å­¦ä¹ ",
        "ç‰¹å¾å·¥ç¨‹",
        "æœ‰ç†å‡½æ•°",
        "æ¨¡å‹é¢„å¤„ç†",
        "Scikit-Learn"
      ],
      "processed_time": "2025-08-25T03:19:07.141951+08:00",
      "is_today_news": true
    },
    {
      "title": "åŸºäºæ·±åº¦å­¦ä¹ çš„å·´è¥¿æŸ”æœ¯æ¯”èµ›å§¿åŠ¿è¯†åˆ«ç³»ç»Ÿå¼€å‘",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1mylqrb/r_building_a_deep_learning_image_model_system_to/",
      "summary": "ä½œè€…æ­£åœ¨å¼€å‘ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«ç³»ç»Ÿï¼Œç”¨äºè¯†åˆ«å·´è¥¿æŸ”æœ¯ï¼ˆBJJï¼‰æ¯”èµ›ä¸­çš„å„ç§ä½ç½®ã€‚è¯¥ç³»ç»Ÿå°†æä¾›ä¸€ä¸ªäº’åŠ¨çš„æ—¶é—´çº¿ï¼Œæ˜¾ç¤ºæ¯”èµ›ä¸­çš„æ‰€æœ‰ä½ç½®å˜åŒ–ï¼Œç”¨æˆ·å¯ä»¥å¿«é€Ÿè·³è½¬åˆ°ç‰¹å®šä½ç½®ï¼ŒæŸ¥çœ‹ä½ç½®è½¬æ¢çš„è¿‡ç¨‹ã€‚ç”¨æˆ·è¿˜å¯ä»¥æœç´¢ç‰¹å®šé€‰æ‰‹ã€ä½ç½®å’Œç»„åˆï¼ˆå¦‚â€œæˆˆç™»Â·ç‘å®‰åœ¨èƒŒéƒ¨æ§åˆ¶ä½ç½®â€ï¼‰ï¼Œå¹¶ç›´æ¥è®¿é—®ç›¸å…³æ¯”èµ›ã€‚é¡¹ç›®è®¡åˆ’æ‰©å±•æ¯”èµ›æ•°æ®åº“å’Œä½ç½®ç±»åˆ«ï¼Œå®ç°æŠ€æœ¯/é™æœè¯†åˆ«ï¼Œå¹¶å»ºç«‹åŸºäºä½ç½®çš„è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿã€‚ä½œè€…æ¬¢è¿æœ‰å…´è¶£è®¨è®ºæˆ–åˆä½œçš„äººå£«è”ç³»ã€‚",
      "content": "Hey all, I'm working on developing AI models that can classify and track positions throughout BJJ matches - and I'm keen to get some thoughts on this idea early on. You can check it out here: https://bjjhq.ai/ Ultimately BJJHQ provides an interactive positional timeline beneath match videos, showing all position changes throughout the match, so you're able to instantly jump to specific positions and see how transitions unfold. The idea is that people would be able to search for not only a competitor, but a specific position and combination (e.g., \"Gordon Ryan in back control\"), and instantly access all matches where that scenario occurs. You would also be able to filter and sort matches by time spent in specific positions. Roadmap: Expanding the match database and position categories Technique/submission recognition Automated scoring system built on this positional foundation Would love to know if anyone would be interested to chat or collaborate on this project ... please reach out if",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "è¯¥ç³»ç»Ÿé€šè¿‡æ·±åº¦å­¦ä¹ å›¾åƒæ¨¡å‹è¯†åˆ«å·´è¥¿æŸ”æœ¯ï¼ˆBJJï¼‰æ¯”èµ›ä¸­çš„ä½ç½®ï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ¯”èµ›åˆ†ææ–¹å¼",
        "ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®ç‰¹å®šä½ç½®å’ŒæŠ€æœ¯ç»„åˆæœç´¢æ¯”èµ›ï¼Œæå¤§åœ°æé«˜äº†è®­ç»ƒå’Œåˆ†æçš„æ•ˆç‡",
        "è¯¥æŠ€æœ¯æœªæ¥æœ‰æœ›æ‰©å±•åˆ°æŠ€æœ¯/é™æœè¯†åˆ«ä»¥åŠåŸºäºä½ç½®åŸºç¡€çš„è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯"
      ],
      "tags": [
        "MachineLearning",
        "æ·±åº¦å­¦ä¹ ",
        "å·´è¥¿æŸ”æœ¯",
        "å§¿åŠ¿è¯†åˆ«",
        "æ¯”èµ›åˆ†æ",
        "AIåº”ç”¨"
      ],
      "processed_time": "2025-08-25T03:19:31.199530+08:00",
      "is_today_news": true
    },
    {
      "title": "AAAIæ˜¯å¦å·²é™ä¸ºäºŒæµä¼šè®®ï¼Ÿ",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1mxrt1y/d_aaai_considered_2nd_tier_now/",
      "summary": "æ‘˜è¦ï¼šæœ‰ç”¨æˆ·åœ¨Redditè®¨è®ºAAAIï¼ˆå›½é™…äººå·¥æ™ºèƒ½è”åˆä¼šè®®ï¼‰æ˜¯å¦åº”è¢«è§†ä¸ºäºŒæµä¼šè®®ã€‚å°½ç®¡AAAIçš„æ¥å—ç‡é€šå¸¸é«˜äºICLRï¼ˆå›½é™…å­¦ä¹ ä»£è¡¨ä¼šè®®ï¼‰ï¼Œä½†AAAIåœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„å½±å“åŠ›å’Œè®¤å¯åº¦ä¸NeurIPSã€ICMLç­‰é¡¶çº§ä¼šè®®ç›¸å½“ã€‚è¯¥è®¨è®ºåæ˜ äº†å­¦æœ¯ç•Œå¯¹ä¼šè®®å±‚çº§åˆ’åˆ†çš„ä¸åŒçœ‹æ³•ï¼Œä»¥åŠå¯¹é«˜è´¨é‡è®ºæ–‡å‘è¡¨å¹³å°çš„é‡è§†ã€‚\n\næœ¬æ–‡è®¨è®ºäº†AAAIä¸é¡¶çº§ä¼šè®®ä¹‹é—´çš„å…³ç³»ï¼Œæé†’å­¦æœ¯ç•Œå’Œç ”ç©¶äººå‘˜åœ¨é€‰æ‹©å‘è¡¨å¹³å°æ—¶åº”ç»¼åˆè€ƒè™‘ä¼šè®®çš„å½±å“åŠ›å’Œè®¤å¯åº¦ã€‚",
      "content": "Isnâ€™t AAAI in the same tier as NeurIPS/ICML/ICLR? ICLR literally has >30% acceptance rate. submitted by /u/Healthy_Horse_2183 [link] [comments]",
      "category": "research_progress",
      "importance": "medium",
      "key_points": [
        "AAAIä¸NeurIPS/ICML/ICLRå¤„äºåŒä¸€çº§åˆ«",
        "ICLRçš„æ¥å—ç‡è¶…è¿‡30%",
        "è®¨è®ºAAAIæ˜¯å¦åº”è¢«è§†ä¸ºç¬¬äºŒæ¢¯é˜Ÿä¼šè®®"
      ],
      "tags": [
        "MachineLearning",
        "AAAI",
        "NeurIPS",
        "ICML",
        "ICLR",
        "ä¼šè®®æ¥å—ç‡"
      ],
      "processed_time": "2025-08-25T03:19:49.433946+08:00",
      "is_today_news": true
    },
    {
      "title": "Neurips 2025: æ˜¯å¦åœ¨ä¼šè®®æœ€åä¸€å¤©æ™šä¸Šæœ‰åç»­æ´»åŠ¨ï¼Ÿ",
      "source": "Redditæœºå™¨å­¦ä¹ ",
      "source_description": "Redditæœºå™¨å­¦ä¹ ç¤¾åŒºçƒ­é—¨è®¨è®º",
      "original_link": "https://www.reddit.com/r/MachineLearning/comments/1myptun/d_neurips_2025_are_there_post_conference_events/",
      "summary": "æ‘˜è¦ï¼šRedditç”¨æˆ·Snoo71505é¦–æ¬¡å‚åŠ Neurips 2025å¤§ä¼šï¼Œè¯¥ä¼šè®®äº2022å¹´11æœˆ2æ—¥è‡³11æœˆ7æ—¥ä¸¾è¡Œã€‚ç”±äºéœ€è¦åœ¨ä¼šè®®ç»“æŸåç«‹å³å‡ºå·®ï¼Œä»–æƒ³çŸ¥é“11æœˆ7æ—¥æ™šä¸Šæ˜¯å¦æœ‰åç»­æ´»åŠ¨ã€‚ä»–ä¸ç¡®å®šæ˜¯å½“å¤©æ™šä¸Šå°±ç¦»å¼€è¿˜æ˜¯æ¬¡æ—¥æ—©ä¸Šå†é£å›å®¶ã€‚è¿™ä¸ªé—®é¢˜å¯¹äºè®¡åˆ’ä½å®¿å’Œè¿”ç¨‹æ—¶é—´çš„å‚ä¼šè€…å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚",
      "content": "Context: Neurips 2025 conference is from Tue, Nov 2 to Sun, Nov 7 This is my first time attending the conference. As I need to travel again right after the conference for personal reasons, I am figuring out on what dates to book the hotels / flights in advance. Are there post conference events on the last day eg: Sun, Nov 7 night? I am not sure if it's better to return right away (on Sun, Nov 7 evening) or fly back later (on Mon, Nov 8 morning)? submitted by /u/Snoo71505 [link] [comments]",
      "category": "other",
      "importance": "low",
      "key_points": [
        "Neurips 2025ä¼šè®®æ—¶é—´ä¸º11æœˆ2æ—¥è‡³11æœˆ7æ—¥",
        "ä½œè€…è€ƒè™‘åœ¨ä¼šè®®æœ€åä¸€å¤©ï¼ˆ11æœˆ7æ—¥ï¼‰æ˜¯å¦æœ‰æ™šä¸Šçš„æ´»åŠ¨",
        "ä½œè€…éœ€è¦åœ¨ä¼šè®®ç»“æŸåç«‹å³è¿”å›è¿˜æ˜¯ç¨æ™šä¸€äº›æ—¶é—´è¿”å›å­˜åœ¨ä¸ç¡®å®šæ€§"
      ],
      "tags": [
        "MachineLearning",
        "Neurips",
        "ä¼šè®®æ—¥ç¨‹",
        "ä¸ªäººè¡Œç¨‹è§„åˆ’",
        "è¿”ç¨‹å®‰æ’",
        "å­¦æœ¯ä¼šè®®"
      ],
      "processed_time": "2025-08-25T03:21:01.756421+08:00",
      "is_today_news": true
    }
  ],
  "generated_time": "2025-08-25T03:21:16.849940+08:00",
  "collection_date": "2025-08-25",
  "raw_articles_count": 8,
  "processed_articles_count": 8
}